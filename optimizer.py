import pandas as pd
import json
import os
from pypfopt import EfficientFrontier, risk_models, expected_returns, HRPOpt
import traceback
import numpy as np
from scipy.optimize import minimize
from scipy.stats import norm
import warnings
import math

# ê²½ê³  ë©”ì‹œì§€ í•„í„°ë§
warnings.filterwarnings('ignore', category=UserWarning, module='pypfopt')

# --- ê²½ë¡œ ì„¤ì • ---
DATA_DIR = "data"
PRICE_DATA_DIR = os.path.join(DATA_DIR, "fund_prices")
MASTER_FILE_PATH = os.path.join(DATA_DIR, "etf_master.json")

def clean_price_data(df):
    """ê°€ê²© ë°ì´í„°ë¥¼ ì •ë¦¬í•˜ê³  ì´ìƒê°’ì„ ì œê±°í•©ë‹ˆë‹¤."""
    # 1. ë¬´í•œê°’ì„ NaNìœ¼ë¡œ ë³€í™˜
    df = df.replace([np.inf, -np.inf], np.nan)
    
    # 2. 0 ë˜ëŠ” ìŒìˆ˜ ê°€ê²©ì„ NaNìœ¼ë¡œ ë³€í™˜
    df = df.where(df > 0, np.nan)
    
    # 3. ê·¹ë‹¨ì ì¸ ì¼ì¼ ìˆ˜ìµë¥  ì œê±° (Â±30% ì´ˆê³¼) - ë” ë³´ìˆ˜ì ìœ¼ë¡œ ì„¤ì •
    returns = df.pct_change()
    outlier_mask = (returns.abs() > 0.3)
    df = df.where(~outlier_mask, np.nan)
    
    # 4. forward fillë¡œ ë‹¨ê¸° ê²°ì¸¡ê°’ ë³´ì™„ (ìµœëŒ€ 3ì¼) - ìƒˆë¡œìš´ pandas ë²„ì „ ëŒ€ì‘
    df = df.ffill(limit=3)
    
    # 5. ì—°ì†ëœ NaNì´ ë„ˆë¬´ ë§ì€ í–‰ ì œê±°
    df = df.dropna(thresh=len(df.columns) * 0.8)  # 80% ì´ìƒì˜ ì»¬ëŸ¼ì— ë°ì´í„°ê°€ ìˆëŠ” í–‰ë§Œ ìœ ì§€
    
    return df

def calculate_trimmed_mean_returns(price_data, trim_ratio=0.3):
    """
    ğŸ†• ìƒˆë¡œìš´ í•¨ìˆ˜: ìƒìœ„/í•˜ìœ„ 30% ì œê±° í›„ í‰ê·  ê³„ì‚°í•˜ëŠ” Trimmed Mean ê¸°ëŒ€ìˆ˜ìµë¥ 
    
    Args:
        price_data (pd.DataFrame): ê°€ê²© ë°ì´í„°
        trim_ratio (float): ì œê±°í•  ë¹„ìœ¨ (0.3 = ìƒìœ„30% + í•˜ìœ„30% ì œê±°)
    
    Returns:
        pd.Series: ì—°ìœ¨í™”ëœ ê¸°ëŒ€ìˆ˜ìµë¥ 
    """
    try:
        print("ğŸ”„ Trimmed Mean ê¸°ëŒ€ìˆ˜ìµë¥  ê³„ì‚° ì¤‘...")
        
        # 1. ì¼ì¼ ìˆ˜ìµë¥  ê³„ì‚°
        returns = price_data.pct_change().dropna()
        print(f"   - ìˆ˜ìµë¥  ë°ì´í„° ê¸°ê°„: {len(returns)}ì¼")
        
        if returns.empty:
            print("   âš ï¸ ìˆ˜ìµë¥  ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            return pd.Series(index=price_data.columns, data=0.0)
        
        # 2. ê° ìì‚°ë³„ë¡œ Trimmed Mean ê³„ì‚°
        trimmed_returns = {}
        
        for ticker in returns.columns:
            # í•´ë‹¹ ìì‚°ì˜ ì¼ì¼ ìˆ˜ìµë¥  ì‹œë¦¬ì¦ˆ (NaN ì œê±°)
            asset_returns = returns[ticker].dropna()
            
            if len(asset_returns) < 10:  # ìµœì†Œ 10ì¼ ë°ì´í„° í•„ìš”
                print(f"   âš ï¸ {ticker}: ë°ì´í„° ë¶€ì¡± ({len(asset_returns)}ì¼)")
                trimmed_returns[ticker] = 0.0
                continue
            
            # 3. ìƒìœ„ 30%, í•˜ìœ„ 30% ì œê±°
            # scipy.stats.trim_meanì„ ì‚¬ìš©í•˜ê±°ë‚˜ ì§ì ‘ êµ¬í˜„
            sorted_returns = asset_returns.sort_values()
            n = len(sorted_returns)
            
            # ì œê±°í•  ê°œìˆ˜ ê³„ì‚° (ì–‘ìª½ì—ì„œ ê°ê° 30%)
            trim_count = int(n * trim_ratio)
            
            # ì–‘ìª½ ê·¹ê°’ ì œê±°
            if trim_count > 0:
                trimmed_data = sorted_returns.iloc[trim_count:-trim_count]
            else:
                trimmed_data = sorted_returns
            
            # 4. ì¤‘ê°„ê°’ë“¤ì˜ í‰ê·  ê³„ì‚°
            if len(trimmed_data) > 0:
                daily_mean = trimmed_data.mean()
                # 5. ì—°ìœ¨í™” (252 ê±°ë˜ì¼ ê¸°ì¤€)
                annual_return = daily_mean * 252
            else:
                annual_return = 0.0
            
            trimmed_returns[ticker] = annual_return
            
            print(f"   - {ticker}: ì›ë³¸ {n}ì¼ â†’ íŠ¸ë¦¼ í›„ {len(trimmed_data)}ì¼ â†’ ì—°ìˆ˜ìµë¥  {annual_return:.2%}")
        
        # 6. pd.Seriesë¡œ ë³€í™˜
        mu_trimmed = pd.Series(trimmed_returns)
        
        # 7. ì´ìƒê°’ ì²˜ë¦¬
        mu_trimmed = mu_trimmed.replace([np.inf, -np.inf], np.nan).fillna(0)
        
        print(f"âœ… Trimmed Mean ê¸°ëŒ€ìˆ˜ìµë¥  ê³„ì‚° ì™„ë£Œ")
        return mu_trimmed
        
    except Exception as e:
        print(f"âŒ Trimmed Mean ê³„ì‚° ì˜¤ë¥˜: {str(e)}")
        # ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
        return pd.Series(index=price_data.columns, data=0.02)  # 2% ê¸°ë³¸ê°’

def safe_annualize_performance(price_data, weights, risk_free_rate=0.02, mu=None):
    """
    âœ… í†µì¼ëœ ìˆ˜ìµë¥  ê³„ì‚°ì„ ì‚¬ìš©í•œ í¬íŠ¸í´ë¦¬ì˜¤ ì„±ê³¼ ì—°ìœ¨í™” ê³„ì‚°
    ì™¸ë¶€ì—ì„œ ê³„ì‚°ëœ mu(Trimmed Mean ê¸°ëŒ€ìˆ˜ìµë¥ )ë¥¼ ìš°ì„  ì‚¬ìš©í•˜ê³ , ì—†ìœ¼ë©´ ë‚´ë¶€ì—ì„œ Trimmed Meanìœ¼ë¡œ ê³„ì‚°
    """
    try:
        # âœ… 1. ì™¸ë¶€ì—ì„œ ì „ë‹¬ë°›ì€ muê°€ ìˆìœ¼ë©´ ê·¸ê²ƒì„ ì‚¬ìš© (ì¼ê´€ì„± ìœ ì§€)
        if mu is not None:
            # ì´ë¡ ì  í¬íŠ¸í´ë¦¬ì˜¤ ìˆ˜ìµë¥  ê³„ì‚°
            portfolio_return = sum(weights.get(ticker, 0) * mu.get(ticker, 0) 
                                 for ticker in mu.index if ticker in weights)
            
            # ê³µë¶„ì‚° í–‰ë ¬ë¡œ ë³€ë™ì„± ê³„ì‚° (ë³€ê²½ ì—†ìŒ)
            if isinstance(price_data, pd.DataFrame) and len(price_data.columns) > 1:
                S = risk_models.sample_cov(price_data)
                tickers = list(weights.keys())
                weights_array = np.array([weights[ticker] for ticker in tickers])
                cov_matrix = S.loc[tickers, tickers].values
                daily_vol = np.sqrt(weights_array.T @ cov_matrix @ weights_array)
                annual_vol = daily_vol 
            else:
                # ë‹¨ì¼ ìì‚°ì¸ ê²½ìš°
                annual_vol = 0.1  # ê¸°ë³¸ê°’
            
            sharpe = (portfolio_return - risk_free_rate) / annual_vol if annual_vol > 0 else 0.0
            return float(portfolio_return), float(annual_vol), float(sharpe)
        
        # âœ… 2. muê°€ ì—†ìœ¼ë©´ Trimmed Meanìœ¼ë¡œ ë‚´ë¶€ ê³„ì‚° (ê¸°ì¡´ EMAì—ì„œ ë³€ê²½)
        else:
            # ğŸ†• Trimmed Mean ê¸°ëŒ€ìˆ˜ìµë¥  ê³„ì‚°
            mu_trimmed = calculate_trimmed_mean_returns(price_data)
            
            # í¬íŠ¸í´ë¦¬ì˜¤ ìˆ˜ìµë¥ 
            portfolio_return = sum(weights.get(ticker, 0) * mu_trimmed.get(ticker, 0) 
                                 for ticker in mu_trimmed.index if ticker in weights)
            
            # ë³€ë™ì„± ê³„ì‚° (ê³µë¶„ì‚° ë°©ì‹ì€ ê·¸ëŒ€ë¡œ ìœ ì§€)
            S = risk_models.sample_cov(price_data)
            tickers = list(weights.keys())
            weights_array = np.array([weights[ticker] for ticker in tickers])
            cov_matrix = S.loc[tickers, tickers].values
            annual_vol = np.sqrt(weights_array.T @ cov_matrix @ weights_array)
            
            # ë³€ë™ì„± ìƒí•œì„  ì„¤ì • (100%)
            annual_vol = min(annual_vol, 1.0)
            
            # ìƒ¤í”„ ë¹„ìœ¨
            sharpe = (portfolio_return - risk_free_rate) / annual_vol if annual_vol > 0 else 0.0
            
            return float(portfolio_return), float(annual_vol), float(sharpe)
        
    except Exception as e:
        print(f"ì„±ê³¼ ì—°ìœ¨í™” ê³„ì‚° ì˜¤ë¥˜: {str(e)}")
        return 0.0, 0.1, 0.0

def get_risk_asset_info(selected_tickers):
    """ìœ„í—˜ìì‚° ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    try:
        with open(MASTER_FILE_PATH, 'r', encoding='utf-8') as f:
            master_df = pd.DataFrame(json.load(f))
            master_df.columns = [col.lower() for col in master_df.columns]
        
        selected_info = master_df[master_df['ticker'].isin(selected_tickers)]
        risk_keywords = ["êµ­ë‚´ì£¼ì‹", "í•´ì™¸ì£¼ì‹", "ëŒ€ì²´íˆ¬ì"]
        risk_tickers = selected_info[selected_info['saa_class'].str.contains('|'.join(risk_keywords), na=False)]['ticker'].tolist()
        return risk_tickers
    except:
        return []

def safe_optimize_with_constraints(mu, S, selected_tickers, target_return, risk_free_rate, price_data, objective="max_sharpe"):
    """ì•ˆì „í•œ ì œì•½ì¡°ê±´ ìµœì í™”ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
    # None ê°’ ì²˜ë¦¬
    if target_return is None:
        target_return = risk_free_rate if risk_free_rate is not None else 0.02
    if risk_free_rate is None:
        risk_free_rate = 0.02
    
    # muì™€ Sì˜ ì»¬ëŸ¼ ìˆœì„œì™€ selected_tickers ìˆœì„œë¥¼ ë§ì¶¤
    if hasattr(mu, 'index'):
        # NaNì´ë‚˜ ë¬´í•œê°’ì´ ìˆëŠ” í‹°ì»¤ ì œê±°
        valid_tickers = []
        for ticker in selected_tickers:
            if ticker in mu.index and not (np.isnan(mu[ticker]) or np.isinf(mu[ticker])):
                valid_tickers.append(ticker)
        
        if len(valid_tickers) < 2:
            raise ValueError("ìœ íš¨í•œ ë°ì´í„°ë¥¼ ê°€ì§„ ìì‚°ì´ 2ê°œ ë¯¸ë§Œì…ë‹ˆë‹¤.")
        
        mu_array = np.array([mu[ticker] for ticker in valid_tickers])
        available_tickers = valid_tickers
    else:
        mu_array = mu
        available_tickers = selected_tickers
    
    if len(available_tickers) != len(selected_tickers):
        print(f"ê²½ê³  : ì¼ë¶€ í‹°ì»¤ì˜ ìˆ˜ìµë¥  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ìš”ì²­: {selected_tickers}, ì‚¬ìš©ê°€ëŠ¥: {available_tickers}")
    
    n = len(available_tickers)
    if n < 2:
        raise ValueError("ìµœì í™”ë¥¼ ìœ„í•´ ìµœì†Œ 2ê°œì˜ ìœ íš¨í•œ ìì‚°ì´ í•„ìš”í•©ë‹ˆë‹¤.")
    
    # ê³µë¶„ì‚° í–‰ë ¬ë„ ìˆœì„œ ë§ì¶¤
    if hasattr(S, 'index'):
        S_array = S.loc[available_tickers, available_tickers].values
    else:
        S_array = S
    
    # ê³µë¶„ì‚° í–‰ë ¬ì˜ íŠ¹ì´ê°’ í™•ì¸
    try:
        np.linalg.cholesky(S_array)
    except np.linalg.LinAlgError:
        # ì •ê·œí™” ì¶”ê°€
        S_array += np.eye(n) * 1e-8
    
    # ì´ˆê¸° ê°€ì¤‘ì¹˜
    x0 = np.array([1/n] * n)
    
    # ì œì•½ì¡°ê±´ ì‹¤í–‰ ê°€ëŠ¥ì„± ê²€ì‚¬
    max_possible_return = np.max(mu_array)
    min_possible_return = np.min(mu_array)
    
    # ì œì•½ì¡°ê±´ ì„¤ì •
    constraints = []
    
    # ê°€ì¤‘ì¹˜ í•©ê³„ = 1
    constraints.append({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})
    
    # ëª©í‘œìˆ˜ìµë¥  ì´ìƒ (ì¡°ì •ëœ ê°’ ì‚¬ìš©)
    constraints.append({'type': 'ineq', 'fun': lambda x: np.dot(x, mu_array) - target_return})

    
    # ê²½ê³„ ì¡°ê±´ (0 <= ê°€ì¤‘ì¹˜ <= 1)
    bounds = [(0.05, 0.65) for _ in range(n)]
    
    # ëª©ì í•¨ìˆ˜ ì •ì˜
    if objective == "max_sharpe":
        def objective_func(x):
            portfolio_return = np.dot(x, mu_array)
            portfolio_vol = np.sqrt(np.dot(x, np.dot(S_array, x)))
            if portfolio_vol == 0 or np.isnan(portfolio_vol):
                return 1e6
            sharpe = (portfolio_return - risk_free_rate) / portfolio_vol
            return -sharpe  # ìµœì†Œí™” ë¬¸ì œì´ë¯€ë¡œ ìŒìˆ˜ ë°˜í™˜
    elif objective == "min_vol":
        def objective_func(x):
            vol = np.sqrt(np.dot(x, np.dot(S_array, x)))
            return vol if not np.isnan(vol) else 1e6
    
    # ì—¬ëŸ¬ ìµœì í™” ë°©ë²•ì„ ìˆœì°¨ì ìœ¼ë¡œ ì‹œë„
    methods = ['SLSQP', 'trust-constr']
    result = None
    
    for method in methods:
        try:
            result = minimize(objective_func, x0, method=method, bounds=bounds, constraints=constraints)
            if result.success and not np.any(np.isnan(result.x)):
                break
            else:
                print(f"{method} ë°©ë²• ì‹¤íŒ¨: {result.message}")
        except Exception as e:
            print(f"{method} ë°©ë²•ì—ì„œ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            continue
    
    # ëª¨ë“  ë°©ë²•ì´ ì‹¤íŒ¨í•˜ë©´ ì œì•½ì¡°ê±´ì„ ì™„í™”í•˜ì—¬ ì¬ì‹œë„
    if result is None or not result.success or np.any(np.isnan(result.x)):
        print("ì œì•½ì¡°ê±´ì„ ì™„í™”í•˜ì—¬ ì¬ì‹œë„í•©ë‹ˆë‹¤...")
        
        # ëª©í‘œìˆ˜ìµë¥ ì„ í‰ê·  ìˆ˜ìµë¥ ë¡œ ì„¤ì •
        adjusted_target_return = np.mean(mu_array)
        print(f"ëª©í‘œìˆ˜ìµë¥ ì„ {target_return:.4f}ì—ì„œ {adjusted_target_return:.4f}ë¡œ ì¡°ì •")
        
        # ì™„í™”ëœ ì œì•½ì¡°ê±´
        relaxed_constraints = []
        relaxed_constraints.append({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})
        relaxed_constraints.append({'type': 'ineq', 'fun': lambda x: np.dot(x, mu_array) - adjusted_target_return})
        
        try:
            result = minimize(objective_func, x0, method='SLSQP', bounds=bounds, constraints=relaxed_constraints)
        except Exception as e:
            print(f"ì™„í™”ëœ ì œì•½ì¡°ê±´ì—ì„œë„ ì‹¤íŒ¨: {str(e)}")
    
    # ìµœí›„ì˜ ìˆ˜ë‹¨: ë™ì¼ê°€ì¤‘ í¬íŠ¸í´ë¦¬ì˜¤ ë°˜í™˜
    if result is None or not result.success or np.any(np.isnan(result.x)):
        print("ìµœì í™” ì‹¤íŒ¨. ë™ì¼ê°€ì¤‘ í¬íŠ¸í´ë¦¬ì˜¤ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.")
        result_weights = np.array([1/n] * n)
        weights = dict(zip(available_tickers, result_weights))
        
        # âœ… í†µì¼ëœ muë¥¼ ì‚¬ìš©í•˜ì—¬ ì„±ê³¼ ê³„ì‚°
        portfolio_return, portfolio_vol, sharpe = safe_annualize_performance(
            price_data[available_tickers], weights, risk_free_rate, mu
        )
        
        return weights, portfolio_return, portfolio_vol, sharpe
    
    weights = dict(zip(available_tickers, result.x))
    
    # âœ… í†µì¼ëœ muë¥¼ ì‚¬ìš©í•˜ì—¬ ì„±ê³¼ ê³„ì‚°
    portfolio_return, portfolio_vol, sharpe = safe_annualize_performance(
        price_data[available_tickers], weights, risk_free_rate, mu
    )
    
    return weights, portfolio_return, portfolio_vol, sharpe

def safe_optimize_risk_parity_with_constraints(mu, S, prices, target_return=None, risk_free_rate=0.02):
    """
    âœ… ì™¸ë¶€ì—ì„œ ê³„ì‚°ëœ mu, Së¥¼ ë°›ì•„ì„œ ì‚¬ìš©í•˜ëŠ” Risk Parity ìµœì í™”
    """
    returns = prices.pct_change().dropna()
    n = returns.shape[1]
    tickers = returns.columns.tolist()
    
    # âœ… ì™¸ë¶€ì—ì„œ ì „ë‹¬ë°›ì€ ê³µë¶„ì‚° í–‰ë ¬ ì‚¬ìš©
    cov_matrix = S.values

    # --- Core Risk Parity Optimization ---
    def risk_budget_objective(weights):
        weights = np.array(weights)
        portfolio_vol = np.sqrt(weights.T @ cov_matrix @ weights)
        if portfolio_vol == 0: return 1e9
        marginal_contrib = cov_matrix @ weights / portfolio_vol
        risk_contrib = weights * marginal_contrib
        target_contrib = portfolio_vol / n
        return np.sum((risk_contrib - target_contrib)**2)

    inv_vol = 1.0 / np.sqrt(np.diag(cov_matrix))
    x0 = inv_vol / np.sum(inv_vol)
    bounds = tuple((0.0, 1.0) for _ in range(n))
    constraints = [{'type': 'eq', 'fun': lambda w: np.sum(w) - 1.0}]
    result = minimize(risk_budget_objective, x0, method='SLSQP', bounds=bounds, constraints=constraints)

    rp_weights = result.x if result.success else x0

    # --- Constraint Handling ---
    weights_array = rp_weights
    
    # âœ… ì™¸ë¶€ì—ì„œ ì „ë‹¬ë°›ì€ mu ì‚¬ìš© (ë‹¤ì‹œ ê³„ì‚°í•˜ì§€ ì•ŠìŒ!)
    current_return = mu.values @ weights_array

    if target_return is not None and current_return < target_return:
        print(f"Initial RP return ({current_return:.2%}) is below target ({target_return:.2%}). Adjusting...")
        def adjustment_objective(weights):
            return np.sum((weights - rp_weights)**2)
        adj_constraints = constraints + [{'type': 'ineq', 'fun': lambda w: w @ mu.values - target_return}]
        adj_result = minimize(adjustment_objective, rp_weights, method='SLSQP', bounds=bounds, constraints=adj_constraints)
        if adj_result.success:
            weights_array = adj_result.x
        else:
            print("Warning: Could not meet target return. Returning original RP portfolio.")
    
    # --- Final Performance Calculation ---
    final_weights = dict(zip(tickers, weights_array))
    
    # âœ… í†µì¼ëœ muë¥¼ ì‚¬ìš©í•˜ì—¬ ì„±ê³¼ ê³„ì‚°
    final_return, annual_volatility, sharpe = safe_annualize_performance(
        prices, final_weights, risk_free_rate, mu
    )

    return final_weights, final_return, annual_volatility, sharpe

def get_optimized_portfolio(selected_tickers, params):
    """
    ğŸ†• Trimmed Mean ê¸°ëŒ€ìˆ˜ìµë¥ ì„ ì‚¬ìš©í•œ í†µì¼ëœ í¬íŠ¸í´ë¦¬ì˜¤ ìµœì í™”
    """
    try:
        print("\n" + "="*50)
        print(" STEP 1: ë°ì´í„° ë¡œë“œ ë° ì •ì œ ".center(50, "="))
        print("="*50)
        print(f"ìš”ì²­ëœ í‹°ì»¤: {selected_tickers}")

        if len(selected_tickers) < 2:
            raise ValueError("ìµœì í™”ë¥¼ ìœ„í•´ 2ê°œ ì´ìƒì˜ ì¢…ëª©ì´ í•„ìš”í•©ë‹ˆë‹¤.")
            
        all_prices = []
        for ticker in selected_tickers:
            file_path = os.path.join(PRICE_DATA_DIR, f"{ticker}.csv")
            if os.path.exists(file_path):
                try:
                    df = pd.read_csv(
                        file_path, 
                        skiprows=3, 
                        header=None,
                        names=['Date', 'Close', 'High', 'Low', 'Open', 'Volume'],
                        index_col='Date',
                        parse_dates=True,
                        on_bad_lines='skip'
                    )
                    
                    df = df[df.index.notna()]
                    df = df[~df.index.duplicated(keep='first')]
                    df['Adj Close'] = df['Close']
                    
                    if not df.empty and 'Adj Close' in df.columns:
                        price_series = df[['Adj Close']].rename(columns={'Adj Close': ticker})
                        price_series = clean_price_data(price_series)
                        
                        if not price_series.empty:
                            all_prices.append(price_series)
                        else:
                            print(f"âš ï¸  ì •ë¦¬ í›„ {ticker}ì˜ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
                    else:
                        print(f"âš ï¸  {ticker}ì˜ ê°€ê²© ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                        
                except Exception as e:
                    print(f"âš ï¸  {ticker} íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {str(e)}")
            else:
                print(f"âš ï¸  íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {file_path}")

        if not all_prices:
            raise FileNotFoundError("ìœ íš¨í•œ ê°€ê²© ë°ì´í„°ë¥¼ ê°€ì§„ ETFê°€ í•˜ë‚˜ë„ ì—†ìŠµë‹ˆë‹¤.")

        price_df_cleaned = pd.concat(all_prices, axis=1, join='outer', sort=True)
        price_df_cleaned = clean_price_data(price_df_cleaned)
        price_df_cleaned = price_df_cleaned.dropna()

        if price_df_cleaned.empty or price_df_cleaned.shape[0] < 10:
            raise ValueError(f"ì„ íƒëœ ETFë“¤ì˜ ê³µí†µëœ ê±°ë˜ ê¸°ê°„ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. (í‹°ì»¤: {selected_tickers})")
        
        available_tickers = list(price_df_cleaned.columns)
        print(f"ìµœì¢… ë¶„ì„ ëŒ€ìƒ í‹°ì»¤: {available_tickers}")
        print(f"ê³µí†µ ë¶„ì„ ê¸°ê°„: {price_df_cleaned.index.min().strftime('%Y-%m-%d')} ~ {price_df_cleaned.index.max().strftime('%Y-%m-%d')} ({len(price_df_cleaned)}ì¼)")
        
        if len(available_tickers) < len(selected_tickers):
            print(f"ê²½ê³ : ì¼ë¶€ í‹°ì»¤ì˜ ë°ì´í„°ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤. ìš”ì²­: {selected_tickers}, ì‚¬ìš©ê°€ëŠ¥: {available_tickers}")
        
        if len(available_tickers) < 2:
            raise ValueError("ìµœì í™”ë¥¼ ìœ„í•´ ìœ íš¨í•œ ë°ì´í„°ë¥¼ ê°€ì§„ 2ê°œ ì´ìƒì˜ ì¢…ëª©ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        
        print("\n" + "="*50)
        print(" STEP 2: ê°œë³„ ìì‚° ì„±ê³¼ ë¶„ì„ (Trimmed Mean ë°©ì‹) ".center(50, "="))
        print("="*50)
        
        # ğŸ†• í•µì‹¬ ìˆ˜ì •ì‚¬í•­: Trimmed Mean ê¸°ëŒ€ìˆ˜ìµë¥ ë¡œ í†µì¼
        print("ğŸ“Š Trimmed Mean ê¸°ëŒ€ìˆ˜ìµë¥  ê³„ì‚° ì¤‘...")
        mu = calculate_trimmed_mean_returns(price_df_cleaned)
        
        # ê³µë¶„ì‚° ê³„ì‚°ì€ ê¸°ì¡´ ë°©ì‹ ê·¸ëŒ€ë¡œ ìœ ì§€
        print("ğŸ“Š ê³µë¶„ì‚° í–‰ë ¬ ê³„ì‚° ì¤‘ (ê¸°ì¡´ ë°©ì‹ ìœ ì§€)...")
        S = risk_models.sample_cov(price_df_cleaned)
        
        print("âœ… ëª¨ë“  í•¨ìˆ˜ê°€ ë™ì¼í•œ Trimmed Mean ê¸°ëŒ€ìˆ˜ìµë¥  ì‚¬ìš©")
        for ticker in available_tickers:
            ticker_return = mu.get(ticker, 0)
            ticker_volatility = np.sqrt(S.loc[ticker, ticker]) 
            print(f"â–¶ {ticker}")
            print(f"  - Trimmed Mean ì—°ìœ¨í™” ê¸°ëŒ€ìˆ˜ìµë¥ : {ticker_return:.2%}")
            print(f"  - ì—°ìœ¨í™” ë³€ë™ì„±: {ticker_volatility:.2%}")

        print("\n" + "="*50)
        print(" STEP 3: í¬íŠ¸í´ë¦¬ì˜¤ ìµœì í™” ì‹¤í–‰ ".center(50, "="))
        print("="*50)
        
        mode = params.get("mode", "MVO")
        
        risk_free_rate = params.get("risk_free_rate") if params.get("risk_free_rate") is not None else 0.02
        target_return = params.get("target_return") if params.get("target_return") is not None else risk_free_rate

        print(f"ìµœì í™” ëª¨ë“œ: {mode}, ë¬´ìœ„í—˜ìˆ˜ìµë¥ : {risk_free_rate:.2%}, ëª©í‘œìˆ˜ìµë¥ : {target_return:.2%}")
        
        # âœ… ëª¨ë“  ìµœì í™” ëª¨ë“œì—ì„œ ë™ì¼í•œ mu, S ì‚¬ìš©
        if mode == "EqualWeight":
            weights, e_ret, ann_vol, sharpe = safe_optimize_with_constraints(
                mu, S, available_tickers, target_return, risk_free_rate, price_df_cleaned, "min_vol"
            )
        elif mode == "RiskParity":
            # âœ… í†µì¼ëœ mu, S ì „ë‹¬
            weights, e_ret, ann_vol, sharpe = safe_optimize_risk_parity_with_constraints(
                mu, S, price_df_cleaned, target_return, risk_free_rate
            )
        elif mode == "MVO":
            mvo_objective = params.get("mvo_objective", "max_sharpe")
            print(f"MVO ëª©ì  í•¨ìˆ˜: {mvo_objective}")
            weights, e_ret, ann_vol, sharpe = safe_optimize_with_constraints(
                mu, S, available_tickers, target_return, risk_free_rate, price_df_cleaned, mvo_objective
            )
        elif mode == "Rebalancing":
            # ğŸ†• ë¦¬ë°¸ëŸ°ì‹± ëª¨ë“œ ì¶”ê°€
            rebalancing_objective = params.get("mvo_objective", "max_sharpe")
            weight_change_limit = params.get("risk_asset_limit", 0.5)  # ë¦¬ë°¸ëŸ°ì‹± ê°•ë„ë¥¼ weight_changeë¡œ ì‚¬ìš©
            current_weights = params.get("current_weights", {})  # í˜„ì¬ ë³´ìœ  ë¹„ì¤‘
            
            print(f"Rebalancing ëª©ì  í•¨ìˆ˜: {rebalancing_objective}")
            print(f"Weight change í•œê³„: {weight_change_limit:.2%}")
            print(f"í˜„ì¬ ë³´ìœ  ë¹„ì¤‘: {current_weights}")
            
            weights, e_ret, ann_vol, sharpe = safe_rebalancing_optimize(
                mu, S, available_tickers, target_return, risk_free_rate, price_df_cleaned, 
                rebalancing_objective, weight_change_limit, current_weights
            )
        else:
            raise ValueError(f"ì•Œ ìˆ˜ ì—†ëŠ” ëª¨ë“œì…ë‹ˆë‹¤: {mode}")

        cleaned_weights = {k: max(0, v) for k, v in weights.items()}
        total_weight = sum(cleaned_weights.values())
        if total_weight > 0:
            cleaned_weights = {k: v/total_weight for k, v in cleaned_weights.items()}
        else:
            cleaned_weights = {k: 1/len(available_tickers) for k in available_tickers}

        print("\n" + "="*50)
        print(" STEP 4: ìµœì¢… ìµœì í™” ê²°ê³¼ (Trimmed Mean í†µì¼) ".center(50, "="))
        print("="*50)
        print("âœ… ëª¨ë“  í•¨ìˆ˜ê°€ ë™ì¼í•œ Trimmed Mean ê¸°ëŒ€ìˆ˜ìµë¥  ì‚¬ìš©")
        print("â–¶ ìµœì  ë¹„ì¤‘:")
        for ticker, weight in cleaned_weights.items():
            print(f"  - {ticker}: {weight:.2%}")
        
        print("\nâ–¶ í¬íŠ¸í´ë¦¬ì˜¤ ì„±ê³¼:")
        print(f"  - ê¸°ëŒ€ìˆ˜ìµë¥ : {e_ret:.2%}")
        print(f"  - ë³€ë™ì„±: {ann_vol:.2%}")
        print(f"  - ìƒ¤í”„ì§€ìˆ˜: {sharpe:.2f}")
        print("="*50 + "\n")
        
        def safe_float(value, default=0.0):
            try:
                f_val = float(value)
                if np.isnan(f_val) or np.isinf(f_val):
                    return default
                return f_val
            except (ValueError, TypeError):
                return default

        performance = {
            "expected_annual_return": safe_float(e_ret),
            "annual_volatility": safe_float(ann_vol),
            "sharpe_ratio": safe_float(sharpe)
        }
        
        return cleaned_weights, performance

    except np.linalg.LinAlgError:
        traceback.print_exc()
        raise ValueError("ì„ íƒëœ ì¢…ëª©ë“¤ì˜ ìƒê´€ê´€ê³„ê°€ ë„ˆë¬´ ë†’ì•„ ê³„ì‚°ì´ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤. ë‹¤ë¥¸ ìì‚° ì¡°í•©ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
    except Exception as e:
        traceback.print_exc()
        raise e
    

def safe_rebalancing_optimize(mu, S, selected_tickers, target_return, risk_free_rate, price_data, 
                            objective, weight_change_limit, current_weights):
    """
    ë¦¬ë°¸ëŸ°ì‹± ì œì•½ì¡°ê±´ì´ í¬í•¨ëœ í¬íŠ¸í´ë¦¬ì˜¤ ìµœì í™”
    
    Args:
        mu: ê¸°ëŒ€ìˆ˜ìµë¥ 
        S: ê³µë¶„ì‚° í–‰ë ¬  
        selected_tickers: ì„ íƒëœ í‹°ì»¤ ëª©ë¡
        target_return: ëª©í‘œ ìˆ˜ìµë¥ 
        risk_free_rate: ë¬´ìœ„í—˜ ìˆ˜ìµë¥ 
        price_data: ê°€ê²© ë°ì´í„°
        objective: ëª©ì  í•¨ìˆ˜ ("max_sharpe" or "min_vol")
        weight_change_limit: ë¹„ì¤‘ ë³€ê²½ í•œê³„ (0.0 ~ 1.0)
        current_weights: í˜„ì¬ ë³´ìœ  ë¹„ì¤‘ ë”•ì…”ë„ˆë¦¬
    """
    # None ê°’ ì²˜ë¦¬
    if target_return is None:
        target_return = risk_free_rate if risk_free_rate is not None else 0.02
    if risk_free_rate is None:
        risk_free_rate = 0.02
    
    # muì™€ Sì˜ ì»¬ëŸ¼ ìˆœì„œì™€ selected_tickers ìˆœì„œë¥¼ ë§ì¶¤
    if hasattr(mu, 'index'):
        # NaNì´ë‚˜ ë¬´í•œê°’ì´ ìˆëŠ” í‹°ì»¤ ì œê±°
        valid_tickers = []
        for ticker in selected_tickers:
            if ticker in mu.index and not (np.isnan(mu[ticker]) or np.isinf(mu[ticker])):
                valid_tickers.append(ticker)
        
        if len(valid_tickers) < 1:
            raise ValueError("ìœ íš¨í•œ ë°ì´í„°ë¥¼ ê°€ì§„ ìì‚°ì´ 1ê°œ ë¯¸ë§Œì…ë‹ˆë‹¤.")
        
        mu_array = np.array([mu[ticker] for ticker in valid_tickers])
        available_tickers = valid_tickers
    else:
        mu_array = mu
        available_tickers = selected_tickers
    
    n = len(available_tickers)
    if n < 1:
        raise ValueError("ë¦¬ë°¸ëŸ°ì‹±ì„ ìœ„í•´ ìµœì†Œ 1ê°œì˜ ìœ íš¨í•œ ìì‚°ì´ í•„ìš”í•©ë‹ˆë‹¤.")
    
    # ê³µë¶„ì‚° í–‰ë ¬ë„ ìˆœì„œ ë§ì¶¤
    if hasattr(S, 'index'):
        if n == 1:
            S_array = np.array([[S.loc[available_tickers[0], available_tickers[0]]]])
        else:
            S_array = S.loc[available_tickers, available_tickers].values
    else:
        S_array = S
    
    # ê³µë¶„ì‚° í–‰ë ¬ì˜ íŠ¹ì´ê°’ í™•ì¸ (ë‹¤ì¤‘ ìì‚°ì¸ ê²½ìš°ë§Œ)
    if n > 1:
        try:
            np.linalg.cholesky(S_array)
        except np.linalg.LinAlgError:
            # ì •ê·œí™” ì¶”ê°€
            S_array += np.eye(n) * 1e-8
    
    # í˜„ì¬ ë¹„ì¤‘ ë²¡í„° ìƒì„±
    current_weights_array = np.array([current_weights.get(ticker, 1/n) for ticker in available_tickers])
    
    # í˜„ì¬ ë¹„ì¤‘ ì •ê·œí™” (í•©ê³„ = 1)
    if np.sum(current_weights_array) > 0:
        current_weights_array = current_weights_array / np.sum(current_weights_array)
    else:
        current_weights_array = np.array([1/n] * n)
    
    # ì´ˆê¸° ê°€ì¤‘ì¹˜ (í˜„ì¬ ë¹„ì¤‘ì—ì„œ ì‹œì‘)
    x0 = current_weights_array.copy()
    
    # ì œì•½ì¡°ê±´ ì„¤ì •
    constraints = []
    
    # ê°€ì¤‘ì¹˜ í•©ê³„ = 1
    constraints.append({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})
    
    # ëª©í‘œìˆ˜ìµë¥  ì´ìƒ (ë‹¨ì¼ ìì‚°ì´ ì•„ë‹Œ ê²½ìš°ë§Œ)
    if n > 1:
        constraints.append({'type': 'ineq', 'fun': lambda x: np.dot(x, mu_array) - target_return})
    
    # ğŸ†• í•µì‹¬: Weight Change ì œì•½ì¡°ê±´ ì¶”ê°€
    # |w_new - w_current|ì˜ í•©ì´ weight_change_limit ì´í•˜
    def weight_change_constraint(x):
        weight_changes = np.abs(x - current_weights_array)
        total_change = np.sum(weight_changes)
        return weight_change_limit - total_change  # >= 0ì´ì–´ì•¼ í•¨
    
    constraints.append({'type': 'ineq', 'fun': weight_change_constraint})
    
    print(f"í˜„ì¬ ë¹„ì¤‘: {dict(zip(available_tickers, current_weights_array))}")
    print(f"Weight change í•œê³„: {weight_change_limit:.2%}")

    # ê²½ê³„ ì¡°ê±´ (0 <= ê°€ì¤‘ì¹˜ <= 1)
    bounds = [(0.0, 1.0) for _ in range(n)]
    
    # ëª©ì í•¨ìˆ˜ ì •ì˜
    if objective == "max_sharpe":
        def objective_func(x):
            portfolio_return = np.dot(x, mu_array)
            if n == 1:
                portfolio_vol = np.sqrt(S_array[0,0])
            else:
                portfolio_vol = np.sqrt(np.dot(x, np.dot(S_array, x)))
            if portfolio_vol == 0 or np.isnan(portfolio_vol):
                return 1e6
            sharpe = (portfolio_return - risk_free_rate) / portfolio_vol
            return -sharpe  # ìµœì†Œí™” ë¬¸ì œì´ë¯€ë¡œ ìŒìˆ˜ ë°˜í™˜
    elif objective == "min_vol":
        def objective_func(x):
            if n == 1:
                vol = np.sqrt(S_array[0,0])
            else:
                vol = np.sqrt(np.dot(x, np.dot(S_array, x)))
            return vol if not np.isnan(vol) else 1e6
    
    # ì—¬ëŸ¬ ìµœì í™” ë°©ë²•ì„ ìˆœì°¨ì ìœ¼ë¡œ ì‹œë„
    methods = ['SLSQP', 'trust-constr']
    result = None
    
    for method in methods:
        try:
            result = minimize(objective_func, x0, method=method, bounds=bounds, constraints=constraints)
            if result.success and not np.any(np.isnan(result.x)):
                break
            else:
                print(f"{method} ë°©ë²• ì‹¤íŒ¨: {result.message}")
        except Exception as e:
            print(f"{method} ë°©ë²•ì—ì„œ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            continue
    
    # ëª¨ë“  ë°©ë²•ì´ ì‹¤íŒ¨í•˜ë©´ weight_change_limitì„ ì™„í™”í•˜ì—¬ ì¬ì‹œë„
    if result is None or not result.success or np.any(np.isnan(result.x)):
        print("ì œì•½ì¡°ê±´ì„ ì™„í™”í•˜ì—¬ ì¬ì‹œë„í•©ë‹ˆë‹¤...")
        
        # weight_change_limitì„ 50% ëŠ˜ë ¤ì„œ ì¬ì‹œë„
        relaxed_limit = min(weight_change_limit * 1.5, 2.0)  # ìµœëŒ€ 200%ê¹Œì§€
        print(f"Weight change í•œê³„ë¥¼ {weight_change_limit:.2%}ì—ì„œ {relaxed_limit:.2%}ë¡œ ì™„í™”")
        
        def relaxed_weight_change_constraint(x):
            weight_changes = np.abs(x - current_weights_array)
            total_change = np.sum(weight_changes)
            return relaxed_limit - total_change
        
        # ì™„í™”ëœ ì œì•½ì¡°ê±´
        relaxed_constraints = [c for c in constraints if c['fun'] != weight_change_constraint]
        relaxed_constraints.append({'type': 'ineq', 'fun': relaxed_weight_change_constraint})
        
        try:
            result = minimize(objective_func, x0, method='SLSQP', bounds=bounds, constraints=relaxed_constraints)
        except Exception as e:
            print(f"ì™„í™”ëœ ì œì•½ì¡°ê±´ì—ì„œë„ ì‹¤íŒ¨: {str(e)}")
    
    # ìµœí›„ì˜ ìˆ˜ë‹¨: í˜„ì¬ ë¹„ì¤‘ ìœ ì§€ (ì•„ì£¼ ì‘ì€ ì¡°ì •ë§Œ)
    if result is None or not result.success or np.any(np.isnan(result.x)):
        print("ìµœì í™” ì‹¤íŒ¨. í˜„ì¬ ë¹„ì¤‘ì—ì„œ ì†Œí­ ì¡°ì •í•©ë‹ˆë‹¤.")
        
        # í˜„ì¬ ë¹„ì¤‘ì—ì„œ 5% ë‚´ì—ì„œë§Œ ì¡°ì •
        small_adjustment = 0.05
        result_weights = current_weights_array.copy()
        
        # ê°€ì¥ ì„±ê³¼ê°€ ì¢‹ì€ ìì‚°ì˜ ë¹„ì¤‘ì„ ì•½ê°„ ëŠ˜ë¦¬ê³ , ë‚˜ìœ ìì‚°ì˜ ë¹„ì¤‘ì„ ì•½ê°„ ì¤„ì„
        if n > 1:
            best_asset_idx = np.argmax(mu_array)
            worst_asset_idx = np.argmin(mu_array)
            
            # 5% ì´ë‚´ì—ì„œ ì¡°ì •
            adjustment = min(small_adjustment, result_weights[worst_asset_idx])
            result_weights[worst_asset_idx] -= adjustment
            result_weights[best_asset_idx] += adjustment
        
        weights = dict(zip(available_tickers, result_weights))
        
        # âœ… í†µì¼ëœ muë¥¼ ì‚¬ìš©í•˜ì—¬ ì„±ê³¼ ê³„ì‚°
        portfolio_return, portfolio_vol, sharpe = safe_annualize_performance(
            price_data[available_tickers] if hasattr(price_data, 'columns') else None, 
            weights, risk_free_rate, mu
        )
        
        return weights, portfolio_return, portfolio_vol, sharpe
    
    weights = dict(zip(available_tickers, result.x))
    
    # âœ… í†µì¼ëœ muë¥¼ ì‚¬ìš©í•˜ì—¬ ì„±ê³¼ ê³„ì‚°
    portfolio_return, portfolio_vol, sharpe = safe_annualize_performance(
        price_data[available_tickers] if hasattr(price_data, 'columns') else None, 
        weights, risk_free_rate, mu
    )
    
    # ğŸ” ê²°ê³¼ ë¶„ì„ ì¶œë ¥
    print(f"\në¦¬ë°¸ëŸ°ì‹± ê²°ê³¼:")
    for ticker in available_tickers:
        old_weight = current_weights.get(ticker, 0)
        new_weight = weights.get(ticker, 0)
        change = new_weight - old_weight
        print(f"  {ticker}: {old_weight:.2%} â†’ {new_weight:.2%} ({change:+.2%})")
    
    total_change = sum(abs(weights.get(ticker, 0) - current_weights.get(ticker, 0)) 
                      for ticker in available_tickers)
    print(f"ì´ ë¹„ì¤‘ ë³€ê²½ëŸ‰: {total_change:.2%} (í•œê³„: {weight_change_limit:.2%})")
    
    return weights, portfolio_return, portfolio_vol, sharpe


def ValueAtRisk(annual_return, annual_vol, risk_free_rate=0.02):
    """
    ì´ë¯¸ ê³„ì‚°ëœ ì—°ê°„ ìˆ˜ìµë¥ ê³¼ ë³€ë™ì„±ìœ¼ë¡œ VaR ê³„ì‚°
    ì •ê·œë¶„í¬ ê°€ì • í•˜ì— ì¢Œì¸¡ 1%, 5%, 10% VaR ê³„ì‚°
    """
    try:
        # VaR ê³„ì‚° (ì •ê·œë¶„í¬ ê°€ì •)
        confidence_levels = [0.99, 0.95, 0.90]  # 1%, 5%, 10% VaR
        var_results = {}
        
        for confidence in confidence_levels:
            # ì •ê·œë¶„í¬ì˜ ë¶„ìœ„ìˆ˜ ê³„ì‚°
            z_score = norm.ppf(1 - confidence)  # ì¢Œì¸¡ ê¼¬ë¦¬ ë¶„ìœ„ìˆ˜
            
            # VaR = ê¸°ëŒ€ìˆ˜ìµë¥  + (Z-score Ã— ë³€ë™ì„±)
            var_1year = annual_return + z_score * annual_vol
            
            confidence_pct = int((1 - confidence) * 100)
            var_results[f"var_{confidence_pct}pct"] = {
                "confidence_level": f"{confidence_pct}%",
                "var_1year": round(var_1year * 100, 2),  # ë°±ë¶„ìœ¨ë¡œ ë³€í™˜
                "var_1year_display": f"{var_1year:.1%}"
            }
        
        return {
            "portfolio_return": round(annual_return * 100, 2),
            "portfolio_volatility": round(annual_vol * 100, 2),
            "var_calculations": var_results
        }
        
    except Exception as e:
        print(f"VaR ê³„ì‚° ì˜¤ë¥˜: {str(e)}")
        return {
            "error": str(e),
            "portfolio_return": 0.0,
            "portfolio_volatility": 0.0,
            "var_calculations": {}
        }


def shortfallrisk(annual_return, annual_vol, risk_free_rate=0.02):
    """
    ì´ë¯¸ ê³„ì‚°ëœ ì—°ê°„ ìˆ˜ìµë¥ ê³¼ ë³€ë™ì„±ìœ¼ë¡œ shortfall risk ê³„ì‚°
    1ë…„~20ë…„ íˆ¬ì ì‹œ ì†ì‹¤í™•ë¥  ê³„ì‚°
    në…„ íˆ¬ìì‹œ: return(mean)*n, vol(std)*sqrt(n)
    """
    try:
        # Shortfall Risk ê³„ì‚° (1ë…„~20ë…„)
        shortfall_results = []
        
        for years in range(1, 21):
            # në…„ íˆ¬ì ì‹œ ê¸°ëŒ€ìˆ˜ìµë¥ ê³¼ ë³€ë™ì„±
            expected_return_n_years = annual_return * years
            volatility_n_years = annual_vol * math.sqrt(years)
            
            # ì†ì‹¤í™•ë¥  ê³„ì‚° (ì •ê·œë¶„í¬ ê°€ì •)
            # P(ìˆ˜ìµë¥  < 0) = Î¦((0 - Î¼) / Ïƒ)
            if volatility_n_years > 0:
                z_score = (0 - expected_return_n_years) / volatility_n_years
                loss_probability = norm.cdf(z_score)
            else:
                loss_probability = 0.0 if expected_return_n_years > 0 else 1.0
            
            shortfall_results.append({
                "years": years,
                "expected_return": round(expected_return_n_years * 100, 2),
                "volatility": round(volatility_n_years * 100, 2),
                "loss_probability": round(loss_probability * 100, 2),
                "loss_probability_display": f"{loss_probability:.1%}"
            })
        
        return {
            "portfolio_annual_return": round(annual_return * 100, 2),
            "portfolio_annual_volatility": round(annual_vol * 100, 2),
            "shortfall_risk_by_years": shortfall_results
        }
        
    except Exception as e:
        print(f"Shortfall Risk ê³„ì‚° ì˜¤ë¥˜: {str(e)}")
        return {
            "error": str(e),
            "portfolio_annual_return": 0.0,
            "portfolio_annual_volatility": 0.0,
            "shortfall_risk_by_years": []
        }