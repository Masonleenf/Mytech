import requests
import pandas as pd
import json
import os
import time
from datetime import datetime, timedelta
from pathlib import Path

class ECOSDataManager:
    def __init__(self, api_key, data_dir="./data"):
        """
        í•œêµ­ì€í–‰ ECOS ë°ì´í„° ê´€ë¦¬ í´ë˜ìŠ¤ (ê°œë³„ CSV íŒŒì¼ ì €ì¥ ë°©ì‹)
        
        Args:
            api_key (str): í•œêµ­ì€í–‰ API í‚¤
            data_dir (str): ë°ì´í„° ì €ì¥ ë””ë ‰í† ë¦¬
        """
        self.api_key = api_key
        self.base_url = "https://ecos.bok.or.kr/api"
        self.data_dir = Path(data_dir)
        
        # CSV íŒŒì¼ ì €ì¥ ê²½ë¡œ (data_manager.pyì™€ ìœ ì‚¬í•œ êµ¬ì¡°)
        self.price_data_dir = self.data_dir / "ecos_prices"
        self.list_file = self.data_dir / "list.csv"
        
        # í´ë” ìƒì„±
        self.price_data_dir.mkdir(parents=True, exist_ok=True)
        
        # API í˜¸ì¶œ ì œí•œ (1ì´ˆë‹¹ 1íšŒ)
        self.last_request_time = 0
        self.request_interval = 1.0
        
    def _rate_limit(self):
        """API í˜¸ì¶œ ì†ë„ ì œí•œ"""
        current_time = time.time()
        time_since_last = current_time - self.last_request_time
        if time_since_last < self.request_interval:
            time.sleep(self.request_interval - time_since_last)
        self.last_request_time = time.time()
    
    def _make_api_request(self, stat_code, item_code1, start_date, end_date, cycle='D', max_retries=3):
        """
        API ìš”ì²­ ì‹¤í–‰
        
        Args:
            stat_code (str): í†µê³„í‘œì½”ë“œ
            item_code1 (str): í•­ëª©ì½”ë“œ1
            start_date (str): ì‹œì‘ì¼ì (YYYYMMDD)
            end_date (str): ì¢…ë£Œì¼ì (YYYYMMDD)
            cycle (str): ì£¼ê¸° (D=ì¼ê°„, M=ì›”ê°„, Q=ë¶„ê¸°, A=ì—°ê°„)
            max_retries (int): ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜
            
        Returns:
            list: API ì‘ë‹µ ë°ì´í„° ë¦¬ìŠ¤íŠ¸ ë˜ëŠ” None
        """
        # ì£¼ê¸° í˜•ì‹ ë³€í™˜
        cycle_mapping = {'D': 'D', 'M': 'M', 'Q': 'QQ', 'A': 'YY'}
        api_cycle = cycle_mapping.get(cycle.upper(), 'D')
        
        # í†µê³„í‘œë³„ í•­ëª©ì½”ë“œ í¬ë§·íŒ… ê·œì¹™
        if stat_code == '817Y002':  # ê¸ˆë¦¬
            formatted_item_code = f"0{str(item_code1).zfill(8)}"
        elif stat_code == '802Y001':  # ì£¼ê°€ì§€ìˆ˜
            formatted_item_code = f"0{str(item_code1).zfill(6)}"
        elif stat_code == '731Y001':  # í™˜ìœ¨
            formatted_item_code = f"0{str(item_code1).zfill(6)}"
        else:
            formatted_item_code = f"0{str(item_code1).zfill(6)}"
        
        url = f"{self.base_url}/StatisticSearch/{self.api_key}/json/kr/1/10000/{stat_code}/{api_cycle}/{start_date}/{end_date}/{formatted_item_code}"
        
        for attempt in range(max_retries):
            try:
                self._rate_limit()
                
                print(f"API ìš”ì²­ ì¤‘: {stat_code} - {formatted_item_code} ({api_cycle}) ({start_date}~{end_date})")
                response = requests.get(url, timeout=60)
                response.raise_for_status()
                
                data = response.json()
                
                # ì—ëŸ¬ ì²´í¬
                if 'RESULT' in data:
                    if data['RESULT']['CODE'] != '0':
                        print(f"API ì—ëŸ¬: {data['RESULT']['MESSAGE']}")
                        if data['RESULT']['CODE'] == '200':  # ë°ì´í„° ì—†ìŒ
                            return None
                        elif data['RESULT']['CODE'] == '602':  # í˜¸ì¶œ ì œí•œ
                            print("API í˜¸ì¶œ ì œí•œ, ëŒ€ê¸° ì¤‘...")
                            time.sleep(5)
                            continue
                        else:
                            return None
                
                # ë°ì´í„° í™•ì¸
                if 'StatisticSearch' in data and 'row' in data['StatisticSearch']:
                    rows = data['StatisticSearch']['row']
                    print(f"âœ… ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {len(rows)}ê±´")
                    return rows
                else:
                    print("âŒ ë°ì´í„° ì—†ìŒ")
                    return None
                    
            except requests.exceptions.RequestException as e:
                print(f"ìš”ì²­ ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}/{max_retries}): {e}")
                if attempt < max_retries - 1:
                    time.sleep(2 ** attempt)  # ì§€ìˆ˜ì  ë°±ì˜¤í”„
                    
            except Exception as e:
                print(f"ì˜ˆì™¸ ë°œìƒ: {e}")
                return None
                
        return None
    
    def load_statistics_list(self):
        """
        list.csvì—ì„œ í†µê³„ ëª©ë¡ ë¡œë“œ (ì¼ë³„ ë°ì´í„°ë§Œ)
        
        Returns:
            list: í†µê³„ ì •ë³´ ë¦¬ìŠ¤íŠ¸
        """
        try:
            df = pd.read_csv(self.list_file)
            
            # ì»¬ëŸ¼ëª… ì •ë¦¬
            df.columns = df.columns.str.strip()
            
            statistics = []
            for _, row in df.iterrows():
                # ì¼ë³„ ë°ì´í„°ë§Œ ì²˜ë¦¬ (periodê°€ 'D'ì¸ ê²ƒë§Œ)
                if str(row['period']).strip().upper() != 'D':
                    continue
                    
                stat_info = {
                    'stat_code': str(row['stat_code']).strip(),
                    'item_code1': int(row['item_code1']),
                    'name': str(row['name']).strip(),
                    'period': str(row['period']).strip(),
                    'unit': str(row['ë‹¨ìœ„']).strip()
                }
                statistics.append(stat_info)
            
            print(f"ğŸ“‹ ì¼ë³„ í†µê³„ ëª©ë¡ ë¡œë“œ ì™„ë£Œ: {len(statistics)}ê°œ")
            return statistics
            
        except Exception as e:
            print(f"âŒ list.csv ë¡œë“œ ì‹¤íŒ¨: {e}")
            return []
    
    def get_csv_file_path(self, item_code1):
        """CSV íŒŒì¼ ê²½ë¡œ ìƒì„±"""
        return self.price_data_dir / f"{item_code1}.csv"
    
    def get_latest_date_from_csv(self, csv_file_path):
        """
        CSV íŒŒì¼ì—ì„œ ìµœì‹  ë‚ ì§œ ì¶”ì¶œ
        
        Args:
            csv_file_path (Path): CSV íŒŒì¼ ê²½ë¡œ
            
        Returns:
            str: ìµœì‹  ë‚ ì§œ (YYYYMMDD) ë˜ëŠ” None
        """
        try:
            if not csv_file_path.exists():
                return None
                
            df = pd.read_csv(csv_file_path)
            if df.empty or 'Date' not in df.columns:
                return None
                
            # ë‚ ì§œ ì»¬ëŸ¼ì„ ì •ë ¬í•´ì„œ ìµœì‹  ë‚ ì§œ ì°¾ê¸°
            df['Date'] = pd.to_datetime(df['Date'], format='%Y%m%d', errors='coerce')
            df = df.dropna(subset=['Date'])
            
            if df.empty:
                return None
                
            latest_date = df['Date'].max()
            return latest_date.strftime('%Y%m%d')
            
        except Exception as e:
            print(f"CSV íŒŒì¼ ë‚ ì§œ í™•ì¸ ì˜¤ë¥˜: {e}")
            return None
    
    def save_data_to_csv(self, item_code1, stat_info, api_data, is_update=False):
        """
        API ë°ì´í„°ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥
        
        Args:
            item_code1 (int): í•­ëª©ì½”ë“œ1
            stat_info (dict): í†µê³„ ì •ë³´
            api_data (list): APIì—ì„œ ë°›ì€ ë°ì´í„°
            is_update (bool): ì—…ë°ì´íŠ¸ ëª¨ë“œì¸ì§€ ì—¬ë¶€
        """
        try:
            csv_file_path = self.get_csv_file_path(item_code1)
            
            # API ë°ì´í„°ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜
            new_df = pd.DataFrame(api_data)
            
            # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì¶”ì¶œ: ë‚ ì§œ, ê°’
            new_df = new_df[['TIME', 'DATA_VALUE']].copy()
            new_df.columns = ['Date', 'Close']
            
            # ë°ì´í„° íƒ€ì… ë³€í™˜
            new_df['Date'] = pd.to_datetime(new_df['Date'], format='%Y%m%d', errors='coerce')
            new_df['Close'] = pd.to_numeric(new_df['Close'], errors='coerce')
            
            # ê²°ì¸¡ì¹˜ ì œê±°
            new_df = new_df.dropna()
            
            # ë‚ ì§œìˆœ ì •ë ¬
            new_df = new_df.sort_values('Date')
            
            # ë‚ ì§œë¥¼ ë‹¤ì‹œ YYYYMMDD ë¬¸ìì—´ë¡œ ë³€í™˜ (CSV ì €ì¥ìš©)
            new_df['Date'] = new_df['Date'].dt.strftime('%Y%m%d')
            
            if is_update and csv_file_path.exists():
                # ê¸°ì¡´ íŒŒì¼ì´ ìˆìœ¼ë©´ ì½ì–´ì„œ ë³‘í•©
                try:
                    existing_df = pd.read_csv(csv_file_path)
                    
                    # ì¤‘ë³µ ì œê±°í•˜ë©´ì„œ ë³‘í•©
                    combined_df = pd.concat([existing_df, new_df], ignore_index=True)
                    combined_df = combined_df.drop_duplicates(subset=['Date'], keep='last')
                    
                    # ë‚ ì§œìˆœ ì •ë ¬
                    combined_df['Date'] = pd.to_datetime(combined_df['Date'], format='%Y%m%d')
                    combined_df = combined_df.sort_values('Date')
                    combined_df['Date'] = combined_df['Date'].dt.strftime('%Y%m%d')
                    
                    # ì €ì¥
                    combined_df.to_csv(csv_file_path, index=False)
                    print(f"    â• ê¸°ì¡´ ë°ì´í„° ì—…ë°ì´íŠ¸: {len(new_df)}ê±´ ì¶”ê°€")
                    
                except Exception as e:
                    print(f"    âŒ ê¸°ì¡´ íŒŒì¼ ë³‘í•© ì‹¤íŒ¨: {e}")
                    # ì‹¤íŒ¨í•˜ë©´ ìƒˆ íŒŒì¼ë¡œ ì €ì¥
                    new_df.to_csv(csv_file_path, index=False)
            else:
                # ìƒˆ íŒŒì¼ë¡œ ì €ì¥
                new_df.to_csv(csv_file_path, index=False)
                print(f"    ğŸ’¾ ìƒˆ íŒŒì¼ ì €ì¥: {len(new_df)}ê±´")
            
        except Exception as e:
            print(f"    âŒ CSV ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def run_auto_update(self):
        """ìë™ ì—…ë°ì´íŠ¸ ì‹¤í–‰ (ê°œë³„ CSV íŒŒì¼ ë°©ì‹)"""
        print("ğŸš€ í•œêµ­ì€í–‰ ECOS ìë™ ë°ì´í„° ì—…ë°ì´íŠ¸ (CSV íŒŒì¼)")
        print("=" * 60)
        
        # í†µê³„ ëª©ë¡ ë¡œë“œ (ì¼ë³„ë§Œ)
        statistics = self.load_statistics_list()
        if not statistics:
            print("âŒ í†µê³„ ëª©ë¡ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        total_stats = len(statistics)
        success_count = 0
        error_count = 0
        update_count = 0
        
        today = datetime.now().strftime('%Y%m%d')
        
        for idx, stat_info in enumerate(statistics, 1):
            stat_code = stat_info['stat_code']
            item_code1 = stat_info['item_code1']
            name = stat_info['name']
            
            print(f"\nğŸ“Š [{idx}/{total_stats}] {name}")
            print(f"    ğŸ“‹ {stat_code} - {item_code1}")
            
            csv_file_path = self.get_csv_file_path(item_code1)
            
            # ì‹œì‘ ë‚ ì§œ ê²°ì •
            start_date = "20000101"  # ìš”ì²­ì‚¬í•­: 2024-01-01ë¶€í„°
            end_date = today
            is_update = False
            
            # ê¸°ì¡´ íŒŒì¼ì´ ìˆìœ¼ë©´ ìµœì‹  ë‚ ì§œë¶€í„° ì—…ë°ì´íŠ¸
            if csv_file_path.exists():
                latest_date = self.get_latest_date_from_csv(csv_file_path)
                if latest_date:
                    try:
                        latest_dt = datetime.strptime(latest_date, '%Y%m%d')
                        today_dt = datetime.strptime(today, '%Y%m%d')
                        date_diff = (today_dt - latest_dt).days
                        
                        # ìµœì‹  ë°ì´í„°ê°€ ì˜¤ëŠ˜ê³¼ ê°™ê±°ë‚˜ ì´í›„ë©´ ìŠ¤í‚µ
                        if latest_date >= today:
                            print(f"    âœ… ì´ë¯¸ ìµœì‹  ë°ì´í„° (ìµœì¢…: {latest_date})")
                            success_count += 1
                            continue
                        # 1-3ì¼ ì°¨ì´ë©´ ì˜ì—…ì¼ ê³ ë ¤í•˜ì—¬ ìŠ¤í‚µ (ì£¼ë§, ê³µíœ´ì¼ ê³ ë ¤)
                        elif date_diff <= 3 and date_diff >= 1:
                            print(f"    âœ… ì˜ì—…ì¼ ê¸°ì¤€ ìµœì‹  (ìµœì¢…: {latest_date}, ì°¨ì´: {date_diff}ì¼)")
                            success_count += 1
                            continue
                    except:
                        # ë‚ ì§œ íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì—…ë°ì´íŠ¸ ì§„í–‰
                        pass
                    
                    # ë‹¤ìŒ ë‚ ë¶€í„° ì˜¤ëŠ˜ê¹Œì§€ ì—…ë°ì´íŠ¸
                    next_date = (datetime.strptime(latest_date, '%Y%m%d') + timedelta(days=1)).strftime('%Y%m%d')
                    start_date = next_date
                    is_update = True
                    print(f"    ğŸ”„ ì¦ë¶„ ì—…ë°ì´íŠ¸: {start_date} ~ {end_date}")
                else:
                    print(f"    ğŸ†• ì „ì²´ ìˆ˜ì§‘: {start_date} ~ {end_date}")
            else:
                print(f"    ğŸ†• ìƒˆ íŒŒì¼ ìƒì„±: {start_date} ~ {end_date}")
            
            # API í˜¸ì¶œ
            try:
                api_data = self._make_api_request(stat_code, item_code1, start_date, end_date, 'D')
                
                if api_data:
                    # CSV íŒŒì¼ë¡œ ì €ì¥
                    self.save_data_to_csv(item_code1, stat_info, api_data, is_update)
                    success_count += 1
                    
                    if is_update or not csv_file_path.exists():
                        update_count += 1
                else:
                    print(f"    âŒ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨")
                    error_count += 1
                    
            except Exception as e:
                print(f"    âŒ ì˜ˆì™¸ ë°œìƒ: {e}")
                error_count += 1
        
        print("\n" + "=" * 60)
        print("ğŸ“ˆ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ")
        print(f"âœ… ì„±ê³µ: {success_count}ê°œ")
        print(f"ğŸ”„ ì—…ë°ì´íŠ¸: {update_count}ê°œ")
        print(f"âŒ ì‹¤íŒ¨: {error_count}ê°œ")
        print(f"ğŸ“ ì €ì¥ ê²½ë¡œ: {self.price_data_dir}")
        
        # ìƒì„±ëœ íŒŒì¼ ëª©ë¡ ì¶œë ¥
        csv_files = list(self.price_data_dir.glob("*.csv"))
        print(f"ğŸ“Š ì´ CSV íŒŒì¼ ìˆ˜: {len(csv_files)}ê°œ")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # API í‚¤ ì„¤ì •
    API_KEY = "AN3AJKNRJDS04779G6XP"  # ì‹¤ì œ API í‚¤
    
    # ë°ì´í„° ë§¤ë‹ˆì € ì´ˆê¸°í™”
    manager = ECOSDataManager(API_KEY)
    
    print("ğŸ¦ í•œêµ­ì€í–‰ ECOS ìë™ ë°ì´í„° ìˆ˜ì§‘ê¸° (CSV ë²„ì „)")
    print(f"ğŸ“… ì‹¤í–‰ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    
    # ìë™ ì—…ë°ì´íŠ¸ ì‹¤í–‰
    manager.run_auto_update()
    
    print(f"\nğŸ í”„ë¡œê·¸ë¨ ì™„ë£Œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

if __name__ == "__main__":
    main()